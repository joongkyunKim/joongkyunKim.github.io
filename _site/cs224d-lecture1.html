<!DOCTYPE html>
<html>
<head>
    <!-- [[! Document Settings ]] -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- [[! Page Meta ]] -->
    <title>[CS224d] Lecture1 : Intro to NLP&Deep Learning</title>
    <meta name="description" content="Deep Learning Review - Postings about what i learned and what i have to learn, especially about Deep Learning" />

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="/assets/images/favicon.ico" >

    <!-- [[! Styles'n'Scripts ]] -->
    <link rel="stylesheet" type="text/css" href="/assets/css/screen.css" />
    <link rel="stylesheet" type="text/css"
          href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400" />
    <link rel="stylesheet" type="text/css" href="/assets/css/syntax.css" />

    <!-- [[! highlight.js ]] -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <!-- [[! Ghost outputs important style and meta data with this tag ]] -->
        <link rel="canonical" href="/" />
    <meta name="referrer" content="origin" />
    <link rel="next" href="/page2/" />

    <meta property="og:site_name" content="Deep Learning Review" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Deep Learning Review" />
    <meta property="og:description" content="Postings about what i learned and what i have to learn, especially about Deep Learning" />
    <meta property="og:url" content="/" />
    <meta property="og:image" content="/assets/images/cover1.jpg" />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Deep Learning Review" />
    <meta name="twitter:description" content="Postings about what i learned and what i have to learn, especially about Deep Learning" />
    <meta name="twitter:url" content="/" />
    <meta name="twitter:image:src" content="/assets/images/cover1.jpg" />

    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Website",
    "publisher": "Deep Learning Review",
    "url": "/",
    "image": "/assets/images/cover1.jpg",
    "description": "Postings about what i learned and what i have to learn, especially about Deep Learning"
}
    </script>

    <meta name="generator" content="Jekyll 3.0.0" />
    <link rel="alternate" type="application/rss+xml" title="Deep Learning Review" href="/feed.xml" />


</head>
<body class="home-template nav-closed">

    <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
        <li class="nav-home " role="presentation"><a href="/">Home</a></li>
        <li class="nav-author " role="presentation"><a href="/author/joongkyunKim">Author</a></li>
        <li class="nav-NLP " role="presentation"><a href="/tag/NLP">NLP</a></li>
        <li class="nav-cs224d " role="presentation"><a href="/tag/cs224d">CS224d</a></li>
    </ul>
    <a class="subscribe-button icon-feed" href="/feed.xml">Subscribe</a>
</div>
<span class="nav-cover"></span>


    <div class="site-wrapper">

        <!-- [[! Everything else gets inserted here ]] -->
        <!-- < default -->

<!-- The comment above "< default" means - insert everything in this file into -->
    <!-- the [body] of the default.hbs template, which contains our header/footer. -->

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<header class="main-header post-head " style="background-image: url(/assets/images/cover1.jpg) ">
    <nav class="main-nav  overlay  clearfix">
        
            <a class="menu-button icon-menu" href="#"><span class="word">Menu</span></a>
        
    </nav>
</header>

<main class="content" role="main">

    <article class="post tag-NLP tag-cs224">

        <header class="post-header">
            <h1 class="post-title">[CS224d] Lecture1 : Intro to NLP&Deep Learning</h1>
            <section class="post-meta">
            <!-- <a href='/'>joongkyunKim</a> -->
            <time class="post-date" datetime="2017-03-22">22 Mar 2017</time>
                <!-- [[tags prefix=" on "]] -->
                
                on
                
                    
                       <a href='/tag/NLP'>Nlp</a>,
                    
                
                    
                       <a href='/tag/cs224d'>Cs224d</a>
                    
                
                
            </section>
        </header>

        <section class="post-content">

            <p>Deep Learning 학습을 위해 CS224d 강의를 보고 강의의 복습 및 정리를 위해 오늘부터 Review 내용을 정리하기로 했다. CS224d : Deep Learning for Natrual Language Processing(이하 NLP) 강의는 Stanford University에서 진행되었고 지속해서 진행되고 있는 강의로 해외뿐만아니라 우리나라에서도 딥러닝 초보 학습자들에게 인기를 모은 강의이다. 현재 2017년에는 CS224n 강의가 새롭게 진행중이지만, 강의 비디오를 볼 수 없는 관계로 youtube에서 강의를 볼 수 있는 2016년 강의인 CS224d를 학습하고 정리한다.</p>

<p>오늘은 Lecture1인 Intro to NLP and Deep Learning 에 대해서 알아보기로 한다.</p>

<ul>
  <li>Lecture slide : <a href="http://joongkyunKim.github.io/downloads/lec1/LectureSlide1.pdf">LectureSlide1</a></li>
  <li>Lecture note  : <a href="http://joongkyunKim.github.io/downloads/lec1/LectureNote1.pdf">Lecturenote1</a></li>
  <li>Video Clip    : <a href="https://www.youtube.com/watch?v=Qy0oEkCZkBI&amp;list=PLlJy-eBtNFt4CSVWYqscHDdP58M3zFHIG&amp;index=1">1강</a></li>
</ul>

<h3 id="lecture1--introduction">Lecture1 : Introduction</h3>

<p>첫 강좌에서는 기본적인 NLP의 개념, 응용과 딥러닝의 개념 및 응용에 대해서 설명하고있다.</p>

<h6 id="nlpnatural-language-processing">NLP(Natural Language Processing)</h6>
<p>NLP는 크게 computer science, artificial intelligence(AI), linguistics(언어학) 분야가 접합된 것으로, 결국엔 컴퓨터가 자연언어를 ‘이해’ 할 수 있게 처리를 해주는것을 의미한다.
본 수업에서는 주로 Syntactic analysis(구문 분석)과 Semantic analysis(의미, 맥락 분석)에 포커스를 맞춰서 수업이 진행된다.</p>

<p>NLP의 응용분야는 spelling checking, keyword search 등과 같이 매우 단순한 분야부터 글의 긍정/부정 분류, 기계 번역, 질문 응답과 같은 어려운 분야까지 다양하게 응용될 수 있다.</p>

<p>NLP에서의 어려운점은 기계는 우리의 언어를 문맥상으로 파악하기 힘든것에 있다. 아래의 예제를 살펴보자</p>

<blockquote>
  <p><em>Kim hit Park and then she [fell/ran]</em></p>
</blockquote>

<p>해당 예제의 경우,  <code class="highlighter-rouge">fell</code>이 선택될 경우에는  <code class="highlighter-rouge">she</code>가 지칭하는 것이  <code class="highlighter-rouge">Park</code>이 되지만 <code class="highlighter-rouge">ran</code>의 경우에는 <code class="highlighter-rouge">she</code>가 지칭하는것이 <code class="highlighter-rouge">Kim</code>이 된다. 이와 같이 어느 동사가 오느냐에 따라 지칭(refer)하는 것이 달라질 수 있으며, 인간은 이 문장을 문맥상으로 이해하여 찾아낼 수 있지만 컴퓨터는 그렇게 하지 못한다. 또한, 이중적인 문장과 같은 경우도 컴퓨터가 올바른 답을 내놓지 못할 수도 있다.</p>

<h6 id="dldeep-learning">DL(Deep Learning)</h6>
<p>딥러닝은 머신러닝(Machine Learning)의 분야 중 하나로, 요즘 computer vision, speech recognition 등과 같은 분야에서 각광받고 있다. 대부분의 머신러닝 방법은 well defined 된 human-designed representation와 input features에 잘 적용이 되며, 최종 예측을 위해 parameter들을 최적화하는 작업이 주가 된다. 반면, 딥러닝의 경우는 이와 달리 human-designed된 feature도 사용하지 않고, raw한 데이터를 넣어서 features 까지 learning해서 구해버린다.
바로 이점이 딥러닝이 요새 각광받고 있는 이유가 될것이다. 특정 분야에 대하여 features를 만들어서 이를 튜닝하려면 해당 분야의 전문 지식(Domain Knowledge)가 상당히 필요하지만, 딥러닝을 이용한다면 데이터를 통해서 모델이 <strong>learn feature itself</strong> 를 통해 features를 만들어주므로, 손수 힘들게 features를 만들필요가 없는것이다!!
이를 위해서는 상당한 computing power (learning time을 줄이기 위해)가 필요한데, 최근 CPU/GPU의 발전과 함께 물만난 고기마냥 딥러닝이 높은 성능을 보여주고 있다.</p>

<h6 id="deep-learning--nlp--deep-nlp">Deep Learning + NLP = Deep NLP</h6>
<p>representation learning 과 deep learning 방법을 이용해서 NLP 문제들을 더 좋은 성능으로 풀어보기 위해 NLP에 딥러닝이 적용되었다. 이를 통해서 NLP 각 영역에서 좋은 성능 향상을 이뤄냈다.</p>

<ol>
  <li>
    <p><strong>Phonology(음운체계)</strong>
<img src="downloads/lec1/phonemes.png" alt="PHONEMES" />
기존에는 위의 표와 같이 정해진 음운체계표를 만들어서 적용을 했지만, 딥러닝이 적용된 현재에는 이러한 음운을 예측하기위해 sound features를 training하고, 결과를 숫자 벡터로 표현한다.</p>
  </li>
  <li>
    <p><strong>Morphology(형태론)</strong>
<img src="downloads/lec1/morphemes.png" alt="morphemes" />
<img src="downloads/lec1/morphology.png" alt="MORPHOLOGY" />
기존에는 위의 표와 같이 단어를 형태소(접두사/어근/접미사 등)의 형태로 나눠서 구분지었지만, 딥러닝을 적용하면서 아래와 같이 각각의 형태소를 마찬가지로 벡터로 표현하여 이를 Neural Network 를 이용해서 두개의 벡터를 하나의 벡터로 combine 하는 형태를 취한다.</p>
  </li>
  <li>
    <p><strong>Semantics(의미론)</strong>
<img src="downloads/lec1/semantics.png" alt="SEMANTIC" />
기존에는 왼쪽의 그림과 같이 Lambda calculus와 같은 특수한 함수들을 이용한다. 이럴경우 각 단어마다의 similarity에 대한 개념이 포함되지 않는다. 딥러닝을 적용하는 경우는 오른쪽과 같은데 각단어,각구문 모두 이전과 같이 벡터로 표현이 되며, Neural Network를 이용하여 두개의 벡터가 하나의 벡터로 합쳐진다.</p>
  </li>
  <li>
    <p><strong>Sentiment Analysis(감정분석)</strong></p>
  </li>
</ol>

<blockquote>
  <p><em>This movie doesn’t care about cleverness, wit or any other kind of intelligent humor.</em></p>
</blockquote>

<p><img src="downloads/lec1/sentiment.png" alt="sentiment" />
기존의 방법이었다면, <code class="highlighter-rouge">Not</code> 의 축약형인 <code class="highlighter-rouge">n't</code> 를 보고 이 문장이 부정적이다, 또는 일정한 단어 조합을 통해서 문장의 긍정/부정을 판별했지만 위의 그림과 같이 딥러닝을 이용하면 각 단계에서 긍정과 부정을 조합하여 최종적인 감정(현 문장에서는 부정(-))이 도출된다. 위에 적용된 알고리즘은 RNN(Recursive Neural Network)이다.</p>

<p><em>사실 해당 판별 결과에서 <code class="highlighter-rouge">care</code>와 그 오른쪽 이하의 부분을 합친 결과가 0(중립) 이라고 나왔지만 이는 알고리즘상에서 miss 한 부분이다. <code class="highlighter-rouge">care</code> 이하 부분을 읽어보면 +(긍정)에 가깝다고 할 수 있다</em></p>

<h6 id="conclusion">Conclusion</h6>
<p>이번시간에는 NLP의 기본적인 개념과 응용 분야, 딥러닝의 발전 이유와 함께 실제 NLP에서 딥러닝이 어떠한 방식으로 적용되고 있는지 개략적인 부분을 살펴봤다. 딥러닝이 적용되면서 기존 NLP 방식과 달리 벡터를 이용하여 이를 Neural Network 에 적용해 최종적인 원하는 결과를 도출하는 공통적인 모습을 보았다.
다음시간에는 실제 글자와 단어가 어떻게 벡터로 표현이 되는지 word2vec에 대해서 알아보겠다. 끝~</p>



        </section>

        <footer class="post-footer">

            <!-- Everything inside the #author tags pulls data from the author -->
            <!-- #author-->

            
            <figure class="author-image">
                <a class="img" href="/author/joongkyunKim" style="background-image: url(/assets/images/myphoto.png)"><span class="hidden">'s Picture</span></a>
            </figure>
            

            <section class="author">
                <h4><a href="/author/joongkyunKim">joongkyunKim</a></h4>

                
                    <p> Undergraduated students@Seoul National University</p>
                
                <div class="author-meta">
                    <span class="author-location icon-location"> Seoul, Korea</span>
                    <span class="author-link icon-link"><a href="http://joongkyunKim.github.io"> joongkyunKim.github.io</a></span>
                </div>
            </section>

            <!-- /author  -->

            <section class="share">
                <h4>Share this post</h4>
                <a class="icon-twitter" href="http://twitter.com/share?text=[CS224d] Lecture1 : Intro to NLP&Deep Learning&amp;url=http://joongkyunKim.github.iocs224d-lecture1"
                    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <span class="hidden">Twitter</span>
                </a>
                <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://joongkyunKim.github.iocs224d-lecture1"
                    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <span class="hidden">Facebook</span>
                </a>
                <a class="icon-google-plus" href="https://plus.google.com/share?url=http://joongkyunKim.github.iocs224d-lecture1"
                   onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <span class="hidden">Google+</span>
                </a>
            </section>

            <!-- Add Disqus Comments -->
            

        </footer>

    </article>

</main>

<aside class="read-next">

    <!-- [[! next_post ]] -->
    
        <a class="read-next-story " style="background-image: url(/assets/images/cover2.jpg)" href="/cs224d-lecture2">
            <section class="post">
                <h2>[CS224d] Lecture2 : Word2vec</h2>
                <p>이번 포스팅에서는 lecture1:introduction 에 이어서 lecture2: Word vectors에 관해서 내용을 정리해보도록 한다. 우선 지난 시간에...</p>
            </section>
        </a>
    
    <!-- [[! /next_post ]] -->
    <!-- [[! prev_post ]] -->
    
    <!-- [[! /prev_post ]] -->
</aside>

<!-- /post -->


        <footer class="site-footer clearfix">
          <section class="copyright"><a href="/">Deep Learning Review</a> &copy; 2017</section>
          <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> using <a href="https://github.com/biomadeira/jasper">Jasper</a></section>
        </footer>
    </div>
    <!-- [[! Ghost outputs important scripts and data with this tag ]] -->
    <script type="text/javascript" src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
    <!-- [[! The main JavaScript file for Casper ]] -->
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="/assets/js/index.js"></script>

    <!-- mathjax config similar to math.stackexchange -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      messageStyle: "none",
      "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
    });
    </script>


    <!-- Add Google Analytics  -->
        <!-- Google Analytics Tracking code -->
     <script>
	    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	    ga('create', '', 'auto');
	    ga('send', 'pageview');

     </script>
</body>
</html>
